#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Coze Like LLM ä½¿ç”¨ç¤ºä¾‹
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from core.llm.coze_like import create_coze_like_llm
from core.llm.types import ELLMType


async def simple_chat_example():
    """ç®€å•çš„èŠå¤©ç¤ºä¾‹"""
    print("ğŸ¤– Coze Like LLM èŠå¤©ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        # åˆ›å»º LLM å®ä¾‹
        llm = await create_coze_like_llm(ELLMType.DOUBAO_THINKING)
        print("âœ… LLM åˆå§‹åŒ–æˆåŠŸ")
        
        # ç¤ºä¾‹å¯¹è¯
        conversations = [
            "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ª Python å¼€å‘è€…",
            "è¯·å¸®æˆ‘è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
            "èƒ½ç»™æˆ‘ä¸€äº› Python ç¼–ç¨‹çš„å»ºè®®å—ï¼Ÿ"
        ]
        
        for i, user_message in enumerate(conversations, 1):
            print(f"\nğŸ‘¤ ç”¨æˆ· {i}: {user_message}")
            
            try:
                response = await llm.completions(user_message)
                print(f"ğŸ¤– åŠ©æ‰‹: {response}")
                
            except Exception as e:
                print(f"âŒ å¯¹è¯å¤±è´¥ï¼š{e}")
        
        print("\nâœ… èŠå¤©ç¤ºä¾‹å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()


async def batch_processing_example():
    """æ‰¹é‡å¤„ç†ç¤ºä¾‹"""
    print("\nğŸ“ æ‰¹é‡å¤„ç†ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        # åˆ›å»º LLM å®ä¾‹
        llm = await create_coze_like_llm(ELLMType.DOUBAO_THINKING)
        
        # æ‰¹é‡å¤„ç†çš„é—®é¢˜åˆ—è¡¨
        questions = [
            "ä»€ä¹ˆæ˜¯åŒºå—é“¾ï¼Ÿ",
            "Python å’Œ JavaScript çš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å¦‚ä½•æé«˜ä»£ç è´¨é‡ï¼Ÿ",
            "ä»€ä¹ˆæ˜¯å¾®æœåŠ¡æ¶æ„ï¼Ÿ",
            "å¦‚ä½•è¿›è¡Œæœ‰æ•ˆçš„é¡¹ç›®ç®¡ç†ï¼Ÿ"
        ]
        
        print(f"å‡†å¤‡å¤„ç† {len(questions)} ä¸ªé—®é¢˜...")
        
        results = []
        for i, question in enumerate(questions, 1):
            print(f"\nå¤„ç†é—®é¢˜ {i}/{len(questions)}: {question}")
            
            try:
                answer = await llm.completions(question)
                results.append({
                    'question': question,
                    'answer': answer,
                    'success': True
                })
                print(f"âœ… å¤„ç†æˆåŠŸï¼Œå›ç­”é•¿åº¦ï¼š{len(answer)}")
                
            except Exception as e:
                results.append({
                    'question': question,
                    'answer': None,
                    'success': False,
                    'error': str(e)
                })
                print(f"âŒ å¤„ç†å¤±è´¥ï¼š{e}")
        
        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r['success']])
        print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆï¼š{successful}/{len(questions)} ä¸ªé—®é¢˜å¤„ç†æˆåŠŸ")
        
        return results
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†ç¤ºä¾‹å¤±è´¥ï¼š{e}")
        return []


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Coze Like LLM ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # è¿è¡Œç¤ºä¾‹
    await simple_chat_example()
    await batch_processing_example()
    
    print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
